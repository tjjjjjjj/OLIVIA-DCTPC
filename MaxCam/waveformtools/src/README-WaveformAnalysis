Overview of TJ's code
Last updated: August 15, 2016
A version of WaveformAnalysis.cc, as it appeared when this Readme was last updated, should be in the same directory as this file under the name README-WaveformAnalysis_cc. Currently this reconstruction corresponds to lines 30~1120 of that file, in ~/tj/DCTPC_soft/MaxCam/waveformtools/src .

Hi there!
You're probably reading this because you have to deal with some undergrad's awful imitation of C++ code and the in-line comments weren't helpful enough.
Well, I'm gonna explain how this waveform reconstruction works right now, in like, reasonably okay detail, so hold firmly onto your socks before they get completely knocked off.



If this Readme is too long, you can probably get away with just:

-Simulation
-First couple sentences of each section
-The description of terminatorsearch() in section VI












For context, we need to understand the simulation code (run in Simulations/v1/code/SimMesh.cc and called by EventGenerator.cc in the same directory). Here's an overview of what it does:


********** S I M U L A T I O N ***********\
*
* 1. Read in the kinematics of each alpha from EventGenerator   
*
* 2. At each point of each alpha's trajectory, electrons are "emitted" from the alpha, in an amount proportional to the energy lost by the alpha at that timestep. Taking into account the height of the alpha, the drift velocity, and longitudinal diffusion, the time when the electrons hit the mesh is computed. The strength of this signal is added stored into a temporary vector (let's call it "Vector 1"). Each element of Vector 1 holds a value proportional to the number of electrons reaching the mesh at a given time step.
*
* 3. The linear rise times and exponential decay times are used to produce a new "Vector 2" from the original Vector 1. Vector 2 represents the ideal waveform that would be produced without any experimental or electronic errors.
*
* 4. Random gaussian noise is added to Vector 2, and the vector is discretized to a certain number of output levels. (for example, on a 12-bit scope, the scope signal will be rounded to the nearest multiple of 2^-12 volts.)
*
*
*
* The final waveform is saved to a separate .root file from the rest of the event information because I couldn't figure out a better way to do it. Sorry, physics person of the future. :( Currently these files are saved to Simulations/v1/waveforms/wfs_.root for use by the reconstruction. Many intermediate vectors/histograms are also saved so that the reconstruction can be calibrated by how well it reconstructs this information.
*                                         /
******************************************


The double-alpha reconstruction (primarily contained in the first half of WaveformAnalysis.cc) essentially works by running the simulation in reverse.

Here's an brief overview of the text-wall below:

0.   Index of functions used in code
I.   Reading in information from file
II.  Un-doing the noise/discretization
III. Un-doing the rise/decay response
IV.  Un-doing Gaussian smearing
V.   Fitting Bragg curves to the resulting histogram
VI.  Running numerical algorithms to determine the vertex, delta-E, etc.
VII. Notes and advice

----------------------------------------\
*****************************************\
0. Index of Functions |-------------------\
----------------------'
Functions are listed alphabetically along with the section of this Readme in which descriptions can be found. (Scroll down a page or so to see the list of objects.)
A section of " -- " means that the function is straightforward enough that the comments in WaveformAnalysis.cc are probably sufficient.

,---------.---------------,
| Section | Function name |
'---------'---------------'

--   absmin()
0.   analyze()
0.   average()
0.   correct()     (See also smooth().)
IV.  deconvolve()
--   deriv()
IV.  deriv2(), deriv4(), deriv6(), deriv8()
--   histspline()
VI.  findRMS()
--   halfsearch()
--   integrate()
--   makekernel()
VI.  maxdevsearch()
--   median()
VI.  minfinder()
III. minprepare()
--   normaldist()
--   normalize()
V.   plottbrag(), plotbraggrev()
--   shifthist()
0.   smooth()
VI.  terminatorsearch() and similar-named functions
I.   TurnKnobs()

 ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^
 *  D E S C R I P T I O N S  *
 v^v^v^v^v^v^v^v^v^v^v^v^v^v^v

analyze(): runs the bulk of the reconstruction. Calls pretty much everything except for reading in tuned variable values (See I.) and saving output variables (See VI.).

average(int j, vector<double>& vec, TH1D* hist): Instead of returning a single bin from a histogram, this allows you to get a weighted average of the bins near bin "j" in the histogram. For example, if "vec" is {1,0,0,0,1}, then this function will return the average of bins j-2 and j+2.

correct(TH1D* hist, double SD, double acc, double factor): For use after smooth(). Essentially, it tries to un-do the "widening" effect that gaussian blurring has, while still keeping the curve smooth. The "factor" variable multiplies the strength of this filter. Typically the SD should be the same as or slightly larger than the SD used in smooth(). Using factor = 1 should work fine if you're not sure.

smooth(TH1D* hist,double SD,double acc): Applies Gaussian blurring with standard deviation SD, and computes the tails of the bell curve out to acc standard deviations. Used extensively in the code as a low-pass filter.

------------------------------------------/
*****************************************{
I. Reading From File |--------------------\
---------------------'

TurnKnobs() reads in the values from a .temp file, currently Simulations/v1/runParameters/LittleDCTPC_far/WfKnobs.temp. (NOTE: a couple of these values (currently TermDerFac, RecSD) are overwritten by the code, so these knobs actually can't be tuned in this file.)

analyze() uses the "braggfile" to read in bragghist and bragghist2. It uses the "rootfile" (currently Simulations/v1/waveforms/wfs_.root) to read in rough_wf, histA3, and histB3, as well as horizontal and vertical positions of the waveform (plotoff/vertoff)

bragghist: a spline curve used to look up the energy of an alpha based on its track length.
bragghist2: an experimentally-determined bragg curve for an alpha in this gas mixture.
(See Section VI for more.)

histA3/B3: the "true" bragg curves produced during simulation, used for calibrating the reconstruction.

------------------------------------------/
*****************************************{
II. Waveform Filtering |------------------\
-----------------------'

First, we apply a low-pass filter in order to deal with noise and limited resolution of the scope. Currently, this is just implemented as smooth() followed by correct(). The best choice of standard deviation of this gaussian filter depends on the width of the waveform; see step III for more on this point.

------------------------------------------/
*****************************************{
III. Signal Response |--------------------\
---------------------'

Next, we peel off the rise and decay responses of the scope to reveal the "true" signal received at the mesh.


The function minprepare(TH1D* wf, TH1D* minfinder_curve) takes in a waveform wf, and spits out a waveform minfinder_curve which can then be analyzed by minfinder() (See VI.). minfinder_curve is also the version of the waveform needed to continue with steps IV./V.

The decay time is exponential, i.e. the waveform will fall by an amount proportional to its height. Based on this we can solve for the "true" signal just from the height and slope of the waveform at each point.

The rise time is very short (~10 ns on the scopes I'm modeling), so I have implemented it simply by shifting the histogram over by a couple bins in minprepare(). There is also a slight "box blur" effect from the rise time, but this is negligible since the Guassian blur caused by the electrons' longitudinal diffusion is much stronger.

minprepare() also computes the width of the waveform at 30% height (wfd_delta), which it uses to set values for rec_SD and termderivfactor.

The first time that minprepare() is run, it generates test_minfinder_curve just to get a rough estimate of the width of the waveform. This is used to calculate a new value of rec_SD; step II is run a second time with this rec_SD value. The resulting waveform is put into step III to generate minfinder_curve; this is the final output of step III.

The value termderivfactor is used later, in step VI.

It is crucial to have reasonably close estimates of the decay time (Td) and time resolution (dt) of the scope for step III to work properly. Currently these values are set to the same ones in the simulation.

------------------------------------------/
*****************************************{
IV. Gaussian Deconvolution |--------------\
---------------------------'

The last major waveform-related step in the reconstruction is to un-do the first step in the simulation: smearing of the signal caused by longitudinal diffusion of the electrons.

Surprisingly, it turns out that Gaussian blurring is perfectly reversible in many cases. Numerically, it gets very messy very fast, so this step will only work well if the scope has a high resolution in both time and voltage. Most of the vertex-finding algorithms described in (VI.) depend on this step, but the minfinder() algorithm can be run without any deconvolution for a rough estimate of the vertex.

I have come across three methods for removing Gaussian blur: (1.) Infinite series of Hermite polynomials; (2.) Fourier analysis; and (3.) Infinite series of differential operators. An excellent reference is doi:10.1088/0266-5611/26/8/085002 .

I implemented the differential operator formula as deconvolve(), where the derivatives deriv_() are estimated with the finite difference method (https://en.wikipedia.org/wiki/Finite_difference).

In theory, the deconvolved waveform (mfc2, short for "minfindercurve2") should be very close to the "Vector 1" described in the simulation. It should look like a pair of Bragg curves, since "electrons arriving over time" is directly tied to "energy lost by alphas as they travel through space".

There are several settings in the .temp file to tune this step; the most important is DeconSD, which is the standard deviation of the Gaussian blur you want to remove. The best approach to find this value is probably trial-and-error, but it is useful to note that DeconSD should be proportional to the square root of the distance of the alpha from the mesh. DeconOrder, which determines how many terms to include from the infinite series. Larger numbers are more effective but also introduce high-frequency artifacts. The Der_Step settings change the step size used to calculate derivatives of the waveform; these are not very sensitive.

,-------,
| TL;DR |
'-------'  
deconvolve() is a formula that is evaluated at every point of the waveform, in order to generate a new waveform. If you suspect you are having problems because of this algorithm, try changing DeconOrder (valid values:2,4,6,8) and DeconSD in the temp file.

------------------------------------------/
*****************************************{
V. Bragg Curves |-------------------------\
----------------'

Many of the vertex-finding algorithms, as well as the energy reconstruction, work by fitting a pair of Bragg curves to the energy curve "mfc2" described in IV.

These are created by plotbragg() and plotbraggrev() and stored in bragghist3 and bragghist4. The vertical and horizontal scale of each curve can be determined by the peak bin of mfc2 corresponding to each alpha's bragg peak. In principle the location of the peaks can be used to determine the position of the bragg curves on the x-axis; in pratice, taking a point on the steep end of the curve (currently the point of 75% height) has been more accurate. (This is done by the halfsearch() function).

The vertical height of each reconstructed bragg curve is a good estimate of the secant of each particle's angle from the z-axis. This means that, given the z-length of each alpha's path alone, we can determine the total length of each path in order to determine their energies. (See VI.)

The function findRMS() provides quick estimates of the RMS-error between the mfc2 curve and the reconstructed bragg curves. Unusually large values here may indicate that the bragg curves are a poor fit. The middle part of the mfc2 curve is excluded from the calculations of rms_left, rms_right, and rms_outer because otherwise the transition between the two bragg curves would dominate the RMS value.

------------------------------------------/
*****************************************{
VI. Analysis |----------------------------\
-------------'

,------------,
| Algorithms |
'------------'

minfinder(TH1D* wf, TH1D* wfder):

wf is the original waveform. wfder is the processed version produced by minprepare() (see III).

Essentially, the algorithm waits for wfder to rise up to a peak, and then locates the first minimum after that peak.

The variables wf, cooldownmax, coolfactor, and threshold are all used in order to ignore "false positives" caused by noisy data or other unexpected errors.

---
terminatorsearch(TH1D* bragghist3, TH1D* bragghist4, TH1D* mfc2, int xmin, int xmax, double threshold, vector<int>& vec, vector<double>& vec2):

This algorithm assumes that the curve mfc2 smoothly transitions from bragghist3 to bragghist4 somewhere near the center of the waveform. In order to find the vertex, it looks for the bin where mfc2 is halfway between the two bragg histograms.

If the variable dermfc is set to a non-zero value, then the algorithm also takes into account the derivative of mfc2 relative to the derivatives of the bragg hists. dermfc is proportional how strongly the derivative of the mfc2 is weighted relatively to the value of mfc2.

There are several other knobs inside this algorithm, but none of them turned out to very well, so I've kept them set to zero (turned off) in WfKnobs.temp.

"(thisval * lastval == -1)" means that thisval has just changed sign; i.e. that there is a zero in the function being calculated at that bin.

vec stores all of the recorded zeroes; vec2 records the distance between the two histograms at each zero, which is used as a heuristic of how good that guess is. (Typically the hists are far apart at the vertex, and false positives are often returned when the hists are close together.) The value in vec which corresponds to the largest value in vec2 is returned as output from this algorithm.

If vec is empty at the end of the algorithm, terminatorsearchbackup() is called instead.

---
terminatorsearchbackup(stuff):

This algorithm pretty much looks for the bin where terminatorsearch() would have come the closest to finding a zero.

It's a bit outdated (e.g. it doesn't take into account the derivatives of the histograms, which was a recent change to terminatorsearch()), and it also has some knobs (TSB_coeff/TSB_pow) that I haven't tested. I haven't gotten around to fixing this algorithm because after some recent changes, it rarely gets called by terminatorsearch() anyway.

---
terminatorsearch2(stuff):

This is basically just a variation of terminatorsearchbackup(). It uses slightly different formulas to determine what value to minimize. This probably also needs updated.

---
terminatorsearch3(stuff):

This simply returns the point where two histograms intersect - in this case, the two bragg curves.

---
maxdevsearch(int xmin, int xmax, TH1D* bragghist3, TH1D* bragghist4, TH1D* mfc2):

This finds the bin where the lesser of "distance between mfc2 and bragghist3" and "distance between mfc2 and bragghist4" is maximized. (distance refers to relative "error", e.g. the distance from 201 to 200 is (201-200)/200 = .005)

,------------------,
| Origin estimates |
'------------------'

jmin: minfinder() applied to minfinder_curve. Pretty robust and works on low-resolution scopes, but not accurate even in theory.

jbragg: minfinder() applied to mfc2. Almost always better as long as deconvolution (IV) works reasonably well on the waveform.

jdiff: minfinder() applied to mfcdiff, which is a histogram simply defined bin-by-bin as minfinder_curve - mfc2.

jterm: terminatorsearch() applied to mfc2 and the best-fit bragg curves. Currently the most reliable estimate by far when using a high-resolution scope.

jterm2: terminatorsearch2() applied to mfc2 and the bragg curves.

jterm3: terminatorsearch3() applied just to the bragg curves. Not a good way to actually get the vertex but is a useful piece of information, for example, to make a single estimate using multiple of the other estimates as input.

maxdevloc: maxdevsearch() applied to mfc2. Also "useful-but-not-a-good-estimate."

,------------------,
| Energy estimates |
'------------------'

leftint/rightint (short for left integral, right integral) are the energy estimates of each alpha based on the reconstructed vertex. They're basically just found by using histspline() to look up the track length of the alpha in the bragghist histogram, which contains an experimentally determined energy-tracklength curve.

leftint2/rightint2 use the true vertex, which is known from the simulation, in order to determine how much error in Delta-E is a result of the vertex-finding and how much is from other sources.

------------------------------------------/
*****************************************{
VII. Misc. Notes |------------------------\
-----------------'

* The low-pass Gaussian filter is a simple trick I just came up with and did not intend as a long-term solution (although it works well enough for now). Other methods, such as Fourier analysis, may be better, but I have not tried them.

* Electron attenuation is currently disabled in the simulation and not accounted for in the reconstruction.

* The deconvolution uses a single, constant standard deviation; ideally, it should be based on how far the alpha is from the mesh, which can change significantly during an event.

* There are quite a vew hard-coded variables that I haven't moved yet. The most worrying is the limits of histograms, from 0 to 16384, with many algorithms using an arbitrary subset of this range. (This was originally done for efficency reasons but is no longer needed.) Using a substantially different timestep or drift velocity could break the code as a result.

* The reconstruction (as well as the simulation) spends most of its CPU time computing Gaussian blurs for various functions. Therefore it runs in roughly O(f^2 * z^.5) time, where f is the frequency of the scope and z is the average height of the alphas. Extremely high-frequency scopes will give better results with this algorithm, but they will also take a very long time to analyze.

* There are plenty of weird experimental effects and electronic quirks that will cause data events to differ significantly from simulated events, in ways that may completely ruin the algorithms used in this code. If anyone in the future is reading this file because my code gives bad results, I would recommend going through the same procedure that I did to make this code in the first place: save a bunch of intermediate steps from the simulation to see what they "should" look like. Run the reconstruction code on data waveforms and plot histograms at each major step. When the reconstructed histograms start to differ significantly from what you expect, you can either (1) improve the algorithm that produced the bad histogram, or (2) introduce a new step that filters/processes the "bad" histogram into one that can be used by the next step in the reconstruction, or (3) throw out the remaining steps of the code, and try to re-implement the general idea of the code with more robust methods.

------------------------------------------/
**************** E N D ******************/
----------------------------------------/

(c) 2016 Dank ASCII Art Industries